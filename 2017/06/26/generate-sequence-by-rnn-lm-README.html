<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title> 使用循环神经网语言模型生成文本</title>
  <meta name="description" content="使用循环神经网语言模型生成文本">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://models.paddlepaddle.org/2017/06/26/generate-sequence-by-rnn-lm-README.html">
  <link rel="alternate" type="application/rss+xml" title="PaddlePaddle Model Zoo" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">PaddlePaddle Model Zoo</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
          
            
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline"> 使用循环神经网语言模型生成文本</h1>
    <p class="post-meta">
      <time datetime="2017-06-26T00:00:00+08:00" itemprop="datePublished">
        
        Jun 26, 2017
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h1 id="使用循环神经网语言模型生成文本">使用循环神经网语言模型生成文本</h1>

<p>语言模型(Language Model)是一个概率分布模型，简单来说，就是用来计算一个句子的概率的模型。利用它可以确定哪个词序列的可能性更大，或者给定若干个词，可以预测下一个最可能出现的词。语言模型是自然语言处理领域里一个重要的基础模型。</p>

<h2 id="应用场景">应用场景</h2>
<p><strong>语言模型被应用在很多领域</strong>，如：</p>

<ul>
  <li><strong>自动写作</strong>：语言模型可以根据上文生成下一个词，递归下去可以生成整个句子、段落、篇章。</li>
  <li><strong>QA</strong>：语言模型可以根据Question生成Answer。</li>
  <li><strong>机器翻译</strong>：当前主流的机器翻译模型大多基于Encoder-Decoder模式，其中Decoder就是一个待条件的语言模型，用来生成目标语言。</li>
  <li><strong>拼写检查</strong>：语言模型可以计算出词序列的概率，一般在拼写错误处序列的概率会骤减，可以用来识别拼写错误并提供改正候选集。</li>
  <li><strong>词性标注、句法分析、语音识别……</strong></li>
</ul>

<h2 id="关于本例">关于本例</h2>
<p>本例实现基于RNN的语言模型，以及利用语言模型生成文本，本例的目录结构如下：</p>

<div class="language-text highlighter-rouge"><pre class="highlight"><code>.
├── data
│   └── train_data_examples.txt        # 示例数据，可参考示例数据的格式，提供自己的数据
├── config.py    # 配置文件，包括data、train、infer相关配置
├── generate.py  # 预测任务脚本，即生成文本
├── beam_search.py    # beam search 算法实现
├── network_conf.py   # 本例中涉及的各种网络结构均定义在此文件中，希望进一步修改模型结构，请修改此文件
├── reader.py    # 读取数据接口
├── README.md
├── train.py    # 训练任务脚本
└── utils.py    # 定义通用的函数，例如：构建字典、加载字典等
</code></pre>
</div>

<h2 id="rnn-语言模型">RNN 语言模型</h2>
<h3 id="简介">简介</h3>

<p>RNN是一个序列模型，基本思路是：在时刻$t$，将前一时刻$t-1$的隐藏层输出和$t$时刻的词向量一起输入到隐藏层从而得到时刻$t$的特征表示，然后用这个特征表示得到$t$时刻的预测输出，如此在时间维上递归下去。可以看出RNN善于使用上文信息、历史知识，具有“记忆”功能。理论上RNN能实现“长依赖”（即利用很久之前的知识），但在实际应用中发现效果并不理想，研究提出了LSTM和GRU等变种，通过引入门机制对传统RNN的记忆单元进行了改进，弥补了传统RNN在学习长序列时遇到的难题。本例模型使用了LSTM或GRU，可通过配置进行修改。下图是RNN（广义上包含了LSTM、GRU等）语言模型“循环”思想的示意图：</p>

<p>&lt;p align=center&gt;<img src="images/rnn.png" width="500px" />&lt;/p&gt;</p>

<h3 id="模型实现">模型实现</h3>

<p>本例中RNN语言模型的实现简介如下：</p>

<ul>
  <li><strong>定义模型参数</strong>：<code class="highlighter-rouge">config.py</code>中定义了模型的参数变量。</li>
  <li><strong>定义模型结构</strong>：<code class="highlighter-rouge">network_conf.py</code>中的<code class="highlighter-rouge">rnn_lm</code><strong>函数</strong>中定义了模型的<strong>结构</strong>，如下：
    <ul>
      <li>输入层：将输入的词（或字）序列映射成向量，即词向量层： <code class="highlighter-rouge">embedding</code>。</li>
      <li>中间层：根据配置实现RNN层，将上一步得到的<code class="highlighter-rouge">embedding</code>向量序列作为输入。</li>
      <li>输出层：使用<code class="highlighter-rouge">softmax</code>归一化计算单词的概率。</li>
      <li>loss：定义多类交叉熵作为模型的损失函数。</li>
    </ul>
  </li>
  <li><strong>训练模型</strong>：<code class="highlighter-rouge">train.py</code>中的<code class="highlighter-rouge">main</code>方法实现了模型的训练，实现流程如下：
    <ul>
      <li>准备输入数据：建立并保存词典、构建train和test数据的reader。</li>
      <li>初始化模型：包括模型的结构、参数。</li>
      <li>构建训练器：demo中使用的是Adam优化算法。</li>
      <li>定义回调函数：构建<code class="highlighter-rouge">event_handler</code>来跟踪训练过程中loss的变化，并在每轮训练结束时保存模型的参数。</li>
      <li>训练：使用trainer训练模型。</li>
    </ul>
  </li>
  <li><strong>生成文本</strong>：<code class="highlighter-rouge">generate.py</code> 实现了文本的生成，实现流程如下：
    <ul>
      <li>加载训练好的模型和词典文件。</li>
      <li>读取<code class="highlighter-rouge">gen_file</code>文件，每行是一个句子的前缀，用<a href="https://github.com/PaddlePaddle/book/blob/develop/08.machine_translation/README.cn.md#柱搜索算法">柱搜索算法(Beam Search)</a>根据前缀生成文本。</li>
      <li>将生成的文本及其前缀保存到文件<code class="highlighter-rouge">gen_result</code>。</li>
    </ul>
  </li>
</ul>

<h2 id="使用说明">使用说明</h2>

<p>运行本例的方法如下：</p>

<ul>
  <li>1，运行<code class="highlighter-rouge">python train.py</code>命令，开始train模型（默认使用RNN），待训练结束。</li>
  <li>2，运行<code class="highlighter-rouge">python generate.py</code>运行文本生成。（输入的文本默认为<code class="highlighter-rouge">data/train_data_examples.txt</code>，生成的文本默认保存到<code class="highlighter-rouge">data/gen_result.txt</code>中。）</li>
</ul>

<p><strong>如果需要使用自己的语料、定制模型，需要修改<code class="highlighter-rouge">config.py</code>中的配置，细节和适配工作详情如下：</strong></p>

<h3 id="语料适配">语料适配</h3>

<ul>
  <li>清洗语料：去除原文中空格、tab、乱码，按需去除数字、标点符号、特殊符号等。</li>
  <li>内容格式：每个句子占一行；每行中的各词之间使用一个空格符分开。</li>
  <li>
    <p>按需要配置<code class="highlighter-rouge">config.py</code>中的如下参数：</p>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code>   <span class="n">train_file</span> <span class="o">=</span> <span class="s">"data/train_data_examples.txt"</span>
   <span class="n">test_file</span> <span class="o">=</span> <span class="s">""</span>

   <span class="n">vocab_file</span> <span class="o">=</span> <span class="s">"data/word_vocab.txt"</span>
   <span class="n">model_save_dir</span> <span class="o">=</span> <span class="s">"models"</span>
</code></pre>
    </div>
    <ol>
      <li><code class="highlighter-rouge">train_file</code>：指定训练数据的路径，<strong>需要预先分词</strong>。</li>
      <li><code class="highlighter-rouge">test_file</code>：指定测试数据的路径，如果训练数据不为空，将在每个 <code class="highlighter-rouge">pass</code> 训练结束对指定的测试数据进行测试。</li>
      <li><code class="highlighter-rouge">vocab_file</code>：指定字典的路径，如果字典文件不存在，将会对训练语料进行词频统计，构建字典。</li>
      <li><code class="highlighter-rouge">model_save_dir</code>：指定模型保存的路径，如果指定的文件夹不存在，将会自动创建。</li>
    </ol>
  </li>
</ul>

<h3 id="构建字典的策略">构建字典的策略</h3>
<ul>
  <li>
    <p>当指定的字典文件不存在时，将对训练数据进行词频统计，自动构建字典<code class="highlighter-rouge">config.py</code> 中有如下两个参数与构建字典有关：</p>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code>  <span class="n">max_word_num</span> <span class="o">=</span> <span class="mi">51200</span> <span class="o">-</span> <span class="mi">2</span>
  <span class="n">cutoff_word_fre</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre>
    </div>
    <ol>
      <li><code class="highlighter-rouge">max_word_num</code>：指定字典中含有多少个词。</li>
      <li><code class="highlighter-rouge">cutoff_word_fre</code>：字典中词语在训练语料中出现的最低频率。</li>
    </ol>
  </li>
  <li>加入指定了 <code class="highlighter-rouge">max_word_num = 5000</code>，并且 <code class="highlighter-rouge">cutoff_word_fre = 10</code>，词频统计发现训练语料中出现频率高于10次的词语仅有3000个，那么最终会取3000个词构成词典。</li>
  <li>构建词典时，会自动加入两个特殊符号：
    <ol>
      <li><code class="highlighter-rouge">&lt;unk&gt;</code>：不出现在字典中的词</li>
      <li><code class="highlighter-rouge">&lt;e&gt;</code>：句子的结束符</li>
    </ol>

    <p><em>注：需要注意的是，词典越大生成的内容越丰富，但训练耗时越久。一般中文分词之后，语料中不同的词能有几万乃至几十万，如果<code class="highlighter-rouge">max_word_num</code>取值过小则导致<code class="highlighter-rouge">&lt;unk&gt;</code>占比过高，如果<code class="highlighter-rouge">max_word_num</code>取值较大，则严重影响训练速度（对精度也有影响）。所以，也有“按字”训练模型的方式，即：把每个汉字当做一个词，常用汉字也就几千个，使得字典的大小不会太大、不会丢失太多信息，但汉语中同一个字在不同词中语义相差很大，有时导致模型效果不理想。建议多试试、根据实际情况选择是“按词训练”还是“按字训练”。</em></p>
  </li>
</ul>

<h3 id="模型适配训练">模型适配、训练</h3>

<ul>
  <li>
    <p>按需调整<code class="highlighter-rouge">config.py</code>中如下配置，来修改 rnn 语言模型的网络结果：</p>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code>  <span class="n">rnn_type</span> <span class="o">=</span> <span class="s">"lstm"</span>  <span class="c"># "gru" or "lstm"</span>
  <span class="n">emb_dim</span> <span class="o">=</span> <span class="mi">256</span>
  <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">256</span>
  <span class="n">stacked_rnn_num</span> <span class="o">=</span> <span class="mi">2</span>
</code></pre>
    </div>
    <ol>
      <li><code class="highlighter-rouge">rnn_type</code>：支持 ”gru“ 或者 ”lstm“ 两种参数，选择使用何种 RNN 单元。</li>
      <li><code class="highlighter-rouge">emb_dim</code>：设置词向量的维度。</li>
      <li><code class="highlighter-rouge">hidden_size</code>：设置 RNN 单元隐层大小。</li>
      <li><code class="highlighter-rouge">stacked_rnn_num</code>：设置堆叠 RNN 单元的个数，构成一个更深的模型。</li>
    </ol>
  </li>
  <li>
    <p>运行<code class="highlighter-rouge">python train.py</code>命令训练模型，模型将被保存到<code class="highlighter-rouge">model_save_dir</code>指定的目录。</p>
  </li>
</ul>

<h3 id="按需生成文本">按需生成文本</h3>

<ul>
  <li>
    <p>按需调整<code class="highlighter-rouge">config.py</code>中以下变量，详解如下：</p>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code>  <span class="n">gen_file</span> <span class="o">=</span> <span class="s">"data/train_data_examples.txt"</span>
  <span class="n">gen_result</span> <span class="o">=</span> <span class="s">"data/gen_result.txt"</span>
  <span class="n">max_gen_len</span> <span class="o">=</span> <span class="mi">25</span>  <span class="c"># the max number of words to generate</span>
  <span class="n">beam_size</span> <span class="o">=</span> <span class="mi">5</span>
  <span class="n">model_path</span> <span class="o">=</span> <span class="s">"models/rnn_lm_pass_00000.tar.gz"</span>
</code></pre>
    </div>
    <ol>
      <li><code class="highlighter-rouge">gen_file</code>：指定输入数据文件，每行是一个句子的前缀，<strong>需要预先分词</strong>。</li>
      <li><code class="highlighter-rouge">gen_result</code>：指定输出文件路径，生成结果将写入此文件。</li>
      <li><code class="highlighter-rouge">max_gen_len</code>：指定每一句生成的话最长长度，如果模型无法生成出<code class="highlighter-rouge">&lt;e&gt;</code>，当生成 <code class="highlighter-rouge">max_gen_len</code> 个词语后，生成过程会自动终止。</li>
      <li><code class="highlighter-rouge">beam_size</code>：Beam Search 算法每一步的展开宽度。</li>
      <li><code class="highlighter-rouge">model_path</code>：指定训练好的模型的路径。</li>
    </ol>

    <p>其中，<code class="highlighter-rouge">gen_file</code> 中保存的是待生成的文本前缀，每个前缀占一行，形如：</p>

    <div class="language-text highlighter-rouge"><pre class="highlight"><code>  若隐若现 地像 幽灵 , 像 死神
</code></pre>
    </div>
    <p>将需要生成的文本前缀按此格式存入文件即可；</p>
  </li>
  <li>
    <p>运行<code class="highlighter-rouge">python generate.py</code>命令运行beam search 算法为输入前缀生成文本，下面是模型生成的结果：</p>

    <div class="language-text highlighter-rouge"><pre class="highlight"><code>  81    若隐若现 地像 幽灵 , 像 死神
  -12.2542    一样 。 他 是 个 怪物 &lt;e&gt;
  -12.6889    一样 。 他 是 个 英雄 &lt;e&gt;
  -13.9877    一样 。 他 是 我 的 敌人 &lt;e&gt;
  -14.2741    一样 。 他 是 我 的 &lt;e&gt;
  -14.6250    一样 。 他 是 我 的 朋友 &lt;e&gt;
</code></pre>
    </div>
    <p>其中：</p>
    <ol>
      <li>第一行 <code class="highlighter-rouge">81    若隐若现 地像 幽灵 , 像 死神</code>以<code class="highlighter-rouge">\t</code>为分隔，共有两列：
        <ul>
          <li>第一列是输入前缀在训练样本集中的序号。</li>
          <li>第二列是输入的前缀。</li>
        </ul>
      </li>
      <li>第二 ~ <code class="highlighter-rouge">beam_size + 1</code> 行是生成结果，同样以 <code class="highlighter-rouge">\t</code> 分隔为两列：
        <ul>
          <li>第一列是该生成序列的对数概率（log probability）。</li>
          <li>第二列是生成的文本序列，正常的生成结果会以符号<code class="highlighter-rouge">&lt;e&gt;</code>结尾，如果没有以<code class="highlighter-rouge">&lt;e&gt;</code>结尾，意味着超过了最大序列长度，生成强制终止。</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">PaddlePaddle Model Zoo</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              PaddlePaddle Model Zoo
            
            </li>
            
            <li><a href="mailto:idl-paddle@baidu.com">idl-paddle@baidu.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/PaddlePaddle"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">PaddlePaddle</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/BaiduResearch"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">BaiduResearch</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>PaddlePaddle, PArallel Distributed Deep LEarning, n Easy-to-use, Efficient, Flexible and Scalable Deep Learning Platform.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
