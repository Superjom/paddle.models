<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title> 神经网络机器翻译模型</title>
  <meta name="description" content="神经网络机器翻译模型">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="/2017/05/24/nmt-without-attention-README.html">
  <link rel="alternate" type="application/rss+xml" title="PaddlePaddle Model Zoo" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">PaddlePaddle Model Zoo</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
            <a class="page-link" href="/about/">About</a>
            
          
            
            
          
            
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline"> 神经网络机器翻译模型</h1>
    <p class="post-meta">
      <time datetime="2017-05-24T00:00:00+08:00" itemprop="datePublished">
        
        May 24, 2017
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h1 id="神经网络机器翻译模型">神经网络机器翻译模型</h1>

<h2 id="背景介绍">背景介绍</h2>
<p>机器翻译利用计算机将源语言转换成目标语言的同义表达，是自然语言处理中重要的研究方向，有着广泛的应用需求，其实现方式也经历了不断地演化。传统机器翻译方法主要基于规则或统计模型，需要人为地指定翻译规则或设计语言特征，效果依赖于人对源语言与目标语言的理解程度。近些年来，深度学习的提出与迅速发展使得特征的自动学习成为可能。深度学习首先在图像识别和语音识别中取得成功，进而在机器翻译等自然语言处理领域中掀起了研究热潮。机器翻译中的深度学习模型直接学习源语言到目标语言的映射，大为减少了学习过程中人的介入，同时显著地提高了翻译质量。本例介绍在PaddlePaddle中如何利用循环神经网络（Recurrent Neural Network, RNN）构建一个端到端（End-to-End）的神经网络机器翻译（Neural Machine Translation, NMT）模型。</p>

<h2 id="模型概览">模型概览</h2>
<p>基于 RNN 的神经网络机器翻译模型遵循编码器－解码器结构，其中的编码器和解码器均是一个循环神经网络。将构成编码器和解码器的两个 RNN 沿时间步展开，得到如下的模型结构图：</p>

<p align="center"><img src="images/encoder-decoder.png" width="90%" align="center" /><br />图 1. 编码器－解码器框架 </p>

<p>神经机器翻译模型的输入输出可以是字符，也可以是词或者短语。不失一般性，本例以基于词的模型为例说明编码器／解码器的工作机制：</p>

<ul>
  <li>
    <p><strong>编码器</strong>：将源语言句子编码成一个向量，作为解码器的输入。解码器的原始输入是表示词的 <code class="highlighter-rouge">id</code> 序列 $w = {w_1, w_2, …, w_T}$，用独热（One-hot）码表示。为了对输入进行降维，同时建立词语之间的语义关联，模型为热独码表示的单词学习一个词嵌入（Word Embedding）表示，也就是常说的词向量，关于词向量的详细介绍请参考 PaddleBook 的<a href="https://github.com/PaddlePaddle/book/blob/develop/04.word2vec/README.cn.md">词向量</a>一章。最后 RNN 单元逐个词地处理输入，得到完整句子的编码向量。</p>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td><strong>解码器</strong>：接受编码器的输入，逐个词地解码出目标语言序列 $u = {u_1, u_2, …, u_{T’}}$。每个时间步，RNN 单元输出一个隐藏向量，之后经 <code class="highlighter-rouge">Softmax</code> 归一化计算出下一个目标词的条件概率，即 $P(u_i</td>
          <td>w, u_1, u_2, …, u_{t-1})$。因此，给定输入 $w$，其对应的翻译结果为 $u$ 的概率则为</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<script type="math/tex; mode=display">P(u_1,u_2,...,u_{T'} | w) = \prod_{t=1}^{t={T'}}p(u_t|w, u_1, u_2, u_{t-1})</script>

<p>以中文到英文的翻译为例，源语言是中文，目标语言是英文。下面是一句源语言分词后的句子</p>

<div class="highlighter-rouge"><pre class="highlight"><code>祝愿 祖国 繁荣 昌盛
</code></pre>
</div>

<p>对应的目标语言英文翻译结果为：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Wish motherland rich and powerful
</code></pre>
</div>

<p>在预处理阶段，准备源语言与目标语言互译的平行语料数据，并分别构建源语言和目标语言的词典；在训练阶段，用这样成对的平行语料训练模型；在模型测试阶段，输入中文句子，模型自动生成对应的英语翻译，然后将生成结果与标准翻译对比进行评估。在机器翻译领域，BLEU 是最流行的自动评估指标之一。</p>

<h3 id="rnn-单元">RNN 单元</h3>
<p>RNN 的原始结构用一个向量来存储隐状态，然而这种结构的 RNN 在训练时容易发生梯度弥散（gradient vanishing），对于长时间的依赖关系难以建模。因此人们对 RNN 单元进行了改进，提出了 LSTM[<a href="#参考文献">1</a>] 和 GRU[<a href="#参考文献">2</a>]，这两种单元以门来控制应该记住的和遗忘的信息，较好地解决了序列数据的长时依赖问题。以本例所用的 GRU 为例，其基本结构如下：</p>

<p align="center">
<img src="images/gru.png" width="90%" align="center" /><br />
图 2. GRU 单元
 </p>

<p>可以看到除了隐含状态以外，GRU 内部还包含了两个门：更新门(Update Gate)、重置门(Reset Gate)。在每一个时间步，门限和隐状态的更新由图 2 右侧的公式决定。这两个门限决定了状态以何种方式更新。</p>

<h3 id="双向编码器">双向编码器</h3>
<p>在上述的基本模型中，编码器在顺序处理输入句子序列时，当前时刻的状态只包含了历史输入信息，而没有未来时刻的序列信息。而对于序列建模，未来时刻的上下文同样包含了重要的信息。可以使用如图 3 所示的这种双向编码器来同时获取当前时刻输入的上下文：</p>
<p align="center">
<img src="images/bidirectional-encoder.png" width="90%" align="center" /><br />
图 3. 双向编码器结构示意图
 </p>

<p>图 3 所示的双向编码器[<a href="#参考文献">3</a>]由两个独立的 RNN 构成，分别从前向和后向对输入序列进行编码，然后将两个 RNN 的输出合并在一起，作为最终的编码输出。
在 PaddlePaddle 中，双向编码器可以很方便地调用相关 APIs 实现：</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">src_word_id</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s">'source_language_word'</span><span class="p">,</span>
    <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="n">source_dict_dim</span><span class="p">))</span>

<span class="c"># source embedding</span>
<span class="n">src_embedding</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
    <span class="nb">input</span><span class="o">=</span><span class="n">src_word_id</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">word_vector_dim</span><span class="p">)</span>

<span class="c"># bidirectional GRU as encoder</span>
<span class="n">encoded_vector</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">bidirectional_gru</span><span class="p">(</span>
    <span class="nb">input</span><span class="o">=</span><span class="n">src_embedding</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="n">encoder_size</span><span class="p">,</span>
    <span class="n">fwd_act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">fwd_gate_act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
    <span class="n">bwd_act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">bwd_gate_act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
    <span class="n">return_seq</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>
</div>

<h3 id="柱搜索beam-search-算法">柱搜索（Beam Search） 算法</h3>
<p>训练完成后的生成阶段，模型根据源语言输入，解码生成对应的目标语言翻译结果。解码时，一个直接的方式是取每一步条件概率最大的词，作为当前时刻的输出。但局部最优并不一定能得到全局最优，即这种做法并不能保证最后得到的完整句子出现的概率最大。如果对解的全空间进行搜索，其代价又过大。为了解决这个问题，通常采用柱搜索（Beam Search）算法。柱搜索是一种启发式的图搜索算法，用一个参数 $k$ 控制搜索宽度，其要点如下：</p>

<p><strong>1</strong>. 在解码的过程中，始终维护 $k$ 个已解码出的子序列；</p>

<p><strong>2</strong>. 在中间时刻 $t$, 对于 $k$ 个子序列中的每个序列，计算下一个词出现的概率并取概率最大的前 $k$ 个词，组合得到 $k^2$ 个新子序列；</p>

<p><strong>3</strong>. 取 <strong>2</strong> 中这些组合序列中概率最大的前 $k$ 个以更新原来的子序列;</p>

<p><strong>4</strong>. 不断迭代下去，直至得到 $k$ 个完整的句子，作为翻译结果的候选。</p>

<p>关于柱搜索的更多介绍，可以参考 PaddleBook 中<a href="https://github.com/PaddlePaddle/book/blob/develop/08.machine_translation/README.cn.md">机器翻译</a>一章中<a href="https://github.com/PaddlePaddle/book/blob/develop/08.machine_translation/README.cn.md#柱搜索算法">柱搜索</a>一节。</p>

<h3 id="无注意力机制的解码器">无注意力机制的解码器</h3>
<ul>
  <li>PaddleBook中<a href="https://github.com/PaddlePaddle/book/blob/develop/08.machine_translation/README.cn.md">机器翻译</a>的相关章节中，已介绍了带注意力机制（Attention Mechanism）的 Encoder-Decoder 结构，本例介绍的则是不带注意力机制的 Encoder-Decoder 结构。关于注意力机制，读者可进一步参考 PaddleBook 和参考文献[<a href="#参考文献">3</a>]。</li>
</ul>

<p>对于流行的RNN单元，PaddlePaddle 已有很好的实现均可直接调用。如果希望在 RNN 每一个时间步实现某些自定义操作，可使用 PaddlePaddle 中的<code class="highlighter-rouge">recurrent_layer_group</code>。首先，自定义单步逻辑函数，再利用函数 <code class="highlighter-rouge">recurrent_group()</code> 循环调用单步逻辑函数处理整个序列。本例中的无注意力机制的解码器便是使用<code class="highlighter-rouge">recurrent_layer_group</code>来实现，其中，单步逻辑函数<code class="highlighter-rouge">gru_decoder_without_attention()</code>相关代码如下：</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># the initialization state for decoder GRU</span>
<span class="n">encoder_last</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">last_seq</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">encoded_vector</span><span class="p">)</span>
<span class="n">encoder_last_projected</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
    <span class="n">size</span><span class="o">=</span><span class="n">decoder_size</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span> <span class="nb">input</span><span class="o">=</span><span class="n">encoder_last</span><span class="p">)</span>

<span class="c"># the step function for decoder GRU</span>
<span class="k">def</span> <span class="nf">gru_decoder_without_attention</span><span class="p">(</span><span class="n">enc_vec</span><span class="p">,</span> <span class="n">current_word</span><span class="p">):</span>
    <span class="s">'''
    Step function for gru decoder
    :param enc_vec: encoded vector of source language
    :type enc_vec: layer object
    :param current_word: current input of decoder
    :type current_word: layer object
    '''</span>
    <span class="n">decoder_mem</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">memory</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s">"gru_decoder"</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">decoder_size</span><span class="p">,</span>
            <span class="n">boot_layer</span><span class="o">=</span><span class="n">encoder_last_projected</span><span class="p">)</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">last_seq</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">enc_vec</span><span class="p">)</span>

    <span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
        <span class="n">size</span><span class="o">=</span><span class="n">decoder_size</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="p">[</span><span class="n">context</span><span class="p">,</span> <span class="n">current_word</span><span class="p">])</span>

    <span class="n">gru_step</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">gru_step</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">"gru_decoder"</span><span class="p">,</span>
        <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
        <span class="n">gate_act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">(),</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">decoder_inputs</span><span class="p">,</span>
        <span class="n">output_mem</span><span class="o">=</span><span class="n">decoder_mem</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="n">decoder_size</span><span class="p">)</span>

     <span class="n">out</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
        <span class="n">size</span><span class="o">=</span><span class="n">target_dict_dim</span><span class="p">,</span>
        <span class="n">bias_attr</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(),</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">gru_step</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>  
</code></pre>
</div>

<p>在模型训练和测试阶段，解码器的行为有很大的不同：</p>

<ul>
  <li><strong>训练阶段</strong>：目标翻译结果的词向量<code class="highlighter-rouge">trg_embedding</code>作为参数传递给单步逻辑<code class="highlighter-rouge">gru_decoder_without_attention()</code>，函数<code class="highlighter-rouge">recurrent_group()</code>循环调用单步逻辑执行，最后计算目标翻译与实际解码的差异cost并返回；</li>
  <li><strong>测试阶段</strong>：解码器根据最后一个生成的词预测下一个词，<code class="highlighter-rouge">GeneratedInput()</code>自动取出模型预测出的概率最高的$k$个词的词向量传递给单步逻辑，<code class="highlighter-rouge">beam_search()</code>函数调用单步逻辑函数<code class="highlighter-rouge">gru_decoder_without_attention()</code>完成柱搜索并作为结果返回。</li>
</ul>

<p>训练和生成的逻辑分别实现在如下的<code class="highlighter-rouge">if-else</code>条件分支中：</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">group_input1</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">StaticInput</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">encoded_vector</span><span class="p">)</span>
<span class="n">group_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">group_input1</span><span class="p">]</span>

<span class="n">decoder_group_name</span> <span class="o">=</span> <span class="s">"decoder_group"</span>
<span class="k">if</span> <span class="n">is_generating</span><span class="p">:</span>
    <span class="n">trg_embedding</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">GeneratedInput</span><span class="p">(</span>
        <span class="n">size</span><span class="o">=</span><span class="n">target_dict_dim</span><span class="p">,</span>
        <span class="n">embedding_name</span><span class="o">=</span><span class="s">"_target_language_embedding"</span><span class="p">,</span>
        <span class="n">embedding_size</span><span class="o">=</span><span class="n">word_vector_dim</span><span class="p">)</span>
    <span class="n">group_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trg_embedding</span><span class="p">)</span>

    <span class="n">beam_gen</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">beam_search</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">decoder_group_name</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="n">gru_decoder_without_attention</span><span class="p">,</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">group_inputs</span><span class="p">,</span>
        <span class="n">bos_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">eos_id</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">beam_size</span><span class="o">=</span><span class="n">beam_size</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">beam_gen</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">trg_embedding</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s">"target_language_word"</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="n">target_dict_dim</span><span class="p">)),</span>
        <span class="n">size</span><span class="o">=</span><span class="n">word_vector_dim</span><span class="p">,</span>
        <span class="n">param_attr</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">attr</span><span class="o">.</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"_target_language_embedding"</span><span class="p">))</span>
    <span class="n">group_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trg_embedding</span><span class="p">)</span>

    <span class="n">decoder</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">recurrent_group</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">decoder_group_name</span><span class="p">,</span>
        <span class="n">step</span><span class="o">=</span><span class="n">gru_decoder_without_attention</span><span class="p">,</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">group_inputs</span><span class="p">)</span>

    <span class="n">lbl</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">"target_language_next_word"</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="n">target_dict_dim</span><span class="p">))</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">classification_cost</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lbl</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cost</span>
</code></pre>
</div>

<h2 id="数据准备">数据准备</h2>
<p>本例所用到的数据来自<a href="http://www-lium.univ-lemans.fr/~schwenk/cslm_joint_paper/">WMT14</a>，该数据集是法文到英文互译的平行语料。用<a href="http://www-lium.univ-lemans.fr/~schwenk/cslm_joint_paper/data/bitexts.tgz">bitexts</a>作为训练数据，<a href="http://www-lium.univ-lemans.fr/~schwenk/cslm_joint_paper/data/dev+test.tgz">dev+test data</a>作为验证与测试数据。在PaddlePaddle中已经封装好了该数据集的读取接口，在首次运行的时候，程序会自动完成下载，用户无需手动完成相关的数据准备。</p>

<h2 id="模型的训练与测试">模型的训练与测试</h2>

<h3 id="模型训练">模型训练</h3>

<p>启动模型训练的十分简单，只需在命令行窗口中执行<code class="highlighter-rouge">python train.py</code>。模型训练阶段 <code class="highlighter-rouge">train.py</code> 脚本中的 <code class="highlighter-rouge">train()</code> 函数依次完成了如下的逻辑：</p>

<p><strong>a) 由网络定义，解析网络结构，初始化模型参数</strong></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># define the network topolgy.</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">seq2seq_net</span><span class="p">(</span><span class="n">source_dict_dim</span><span class="p">,</span> <span class="n">target_dict_dim</span><span class="p">)</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</code></pre>
</div>

<p><strong>b) 设定训练过程中的优化策略、定义训练数据读取 <code class="highlighter-rouge">reader</code></strong></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># define optimization method</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">RMSProp</span><span class="p">(</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">gradient_clipping_threshold</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span>
    <span class="n">regularization</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">L2Regularization</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">8e-4</span><span class="p">))</span>

<span class="c"># define the trainer instance</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">cost</span><span class="o">=</span><span class="n">cost</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="n">update_equation</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="c"># define data reader</span>
<span class="n">wmt14_reader</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
    <span class="n">paddle</span><span class="o">.</span><span class="n">reader</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span>
        <span class="n">paddle</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">wmt14</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">source_dict_dim</span><span class="p">),</span> <span class="n">buf_size</span><span class="o">=</span><span class="mi">8192</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">55</span><span class="p">)</span>
</code></pre>
</div>

<p><strong>c) 定义事件句柄，打印训练中间结果、保存模型快照</strong></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># define the event_handler callback</span>
<span class="k">def</span> <span class="nf">event_handler</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">paddle</span><span class="o">.</span><span class="n">event</span><span class="o">.</span><span class="n">EndIteration</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="ow">and</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span>
                                 <span class="s">"nmt_without_att_</span><span class="si">%05</span><span class="s">d_batch_</span><span class="si">%05</span><span class="s">d.tar.gz"</span> <span class="o">%</span>
                                 <span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span><span class="p">),</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="n">parameters</span><span class="o">.</span><span class="n">to_tar</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">%</span> <span class="mi">10</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"Pass </span><span class="si">%</span><span class="s">d, Batch </span><span class="si">%</span><span class="s">d, Cost </span><span class="si">%</span><span class="s">f, </span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">cost</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">metrics</span><span class="p">))</span>
</code></pre>
</div>

<p><strong>d) 开始训练</strong></p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># start training</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">reader</span><span class="o">=</span><span class="n">wmt14_reader</span><span class="p">,</span> <span class="n">event_handler</span><span class="o">=</span><span class="n">event_handler</span><span class="p">,</span> <span class="n">num_passes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre>
</div>

<p>输出样例为</p>

<div class="language-text highlighter-rouge"><pre class="highlight"><code>Pass 0, Batch 0, Cost 267.674663, {'classification_error_evaluator': 1.0}
.........
Pass 0, Batch 10, Cost 172.892294, {'classification_error_evaluator': 0.953895092010498}
.........
Pass 0, Batch 20, Cost 177.989329, {'classification_error_evaluator': 0.9052488207817078}
.........
Pass 0, Batch 30, Cost 153.633665, {'classification_error_evaluator': 0.8643803596496582}
.........
Pass 0, Batch 40, Cost 168.170543, {'classification_error_evaluator': 0.8348183631896973}
</code></pre>
</div>

<h3 id="生成翻译结果">生成翻译结果</h3>
<p>利用训练好的模型生成翻译文本也十分简单。</p>

<ol>
  <li>
    <p>首先请修改<code class="highlighter-rouge">generate.py</code>脚本中<code class="highlighter-rouge">main</code>中传递给<code class="highlighter-rouge">generate</code>函数的参数，以选择使用哪一个保存的模型来生成。默认参数如下所示：</p>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code> <span class="n">generate</span><span class="p">(</span>
     <span class="n">source_dict_dim</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span>
     <span class="n">target_dict_dim</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span>
     <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
     <span class="n">beam_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
     <span class="n">model_path</span><span class="o">=</span><span class="s">"models/nmt_without_att_params_batch_00100.tar.gz"</span><span class="p">)</span>
</code></pre>
    </div>
  </li>
  <li>
    <p>在终端执行命令 <code class="highlighter-rouge">python generate.py</code>，脚本中的<code class="highlighter-rouge">generate()</code>执行了依次如下逻辑：</p>

    <p><strong>a) 加载测试样本</strong></p>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code> <span class="c"># load data  samples for generation</span>
 <span class="n">gen_creator</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">wmt14</span><span class="o">.</span><span class="n">gen</span><span class="p">(</span><span class="n">source_dict_dim</span><span class="p">)</span>
 <span class="n">gen_data</span> <span class="o">=</span> <span class="p">[]</span>
 <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">gen_creator</span><span class="p">():</span>
     <span class="n">gen_data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">))</span>
</code></pre>
    </div>

    <p><strong>b) 初始化模型，执行<code class="highlighter-rouge">infer()</code>为每个输入样本生成<code class="highlighter-rouge">beam search</code>的翻译结果</strong></p>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code> <span class="n">beam_gen</span> <span class="o">=</span> <span class="n">seq2seq_net</span><span class="p">(</span><span class="n">source_dict_dim</span><span class="p">,</span> <span class="n">target_dict_dim</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
 <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">init_models_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
     <span class="n">parameters</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">Parameters</span><span class="o">.</span><span class="n">from_tar</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
 <span class="c"># prob is the prediction probabilities, and id is the prediction word.</span>
 <span class="n">beam_result</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span>
     <span class="n">output_layer</span><span class="o">=</span><span class="n">beam_gen</span><span class="p">,</span>
     <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
     <span class="nb">input</span><span class="o">=</span><span class="n">gen_data</span><span class="p">,</span>
     <span class="n">field</span><span class="o">=</span><span class="p">[</span><span class="s">'prob'</span><span class="p">,</span> <span class="s">'id'</span><span class="p">])</span>
</code></pre>
    </div>

    <p><strong>c) 加载源语言和目标语言词典，将<code class="highlighter-rouge">id</code>序列表示的句子转化成原语言并输出结果</strong></p>

    <div class="language-python highlighter-rouge"><pre class="highlight"><code> <span class="n">beam_result</span> <span class="o">=</span> <span class="n">inferer</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">test_batch</span><span class="p">,</span> <span class="n">field</span><span class="o">=</span><span class="p">[</span><span class="s">"prob"</span><span class="p">,</span> <span class="s">"id"</span><span class="p">])</span>

 <span class="n">gen_sen_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">beam_result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
 <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">gen_sen_idx</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_batch</span><span class="p">)</span> <span class="o">*</span> <span class="n">beam_size</span>

 <span class="n">start_pos</span><span class="p">,</span> <span class="n">end_pos</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span>
 <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_batch</span><span class="p">):</span>
     <span class="k">print</span><span class="p">(</span><span class="s">" "</span><span class="o">.</span><span class="n">join</span><span class="p">([</span>
         <span class="n">src_dict</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
     <span class="p">]))</span>  <span class="c"># skip the start and ending mark when print the source sentence</span>
     <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">beam_size</span><span class="p">):</span>
         <span class="n">end_pos</span> <span class="o">=</span> <span class="n">gen_sen_idx</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="n">beam_size</span> <span class="o">+</span> <span class="n">j</span><span class="p">]</span>
         <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="si">%.4</span><span class="s">f</span><span class="se">\t</span><span class="si">%</span><span class="s">s"</span> <span class="o">%</span> <span class="p">(</span><span class="n">beam_result</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="s">" "</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
             <span class="n">trg_dict</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">beam_result</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">start_pos</span><span class="p">:</span><span class="n">end_pos</span><span class="p">])))</span>
         <span class="n">start_pos</span> <span class="o">=</span> <span class="n">end_pos</span> <span class="o">+</span> <span class="mi">2</span>
     <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
</code></pre>
    </div>
  </li>
</ol>

<p>设置beam search的宽度为3，输入为一个法文句子，则自动为测试数据生成对应的翻译结果，输出格式如下：</p>

<div class="language-text highlighter-rouge"><pre class="highlight"><code>Elles connaissent leur entreprise mieux que personne .
-3.754819        They know their business better than anyone . &lt;e&gt;
-4.445528        They know their businesses better than anyone . &lt;e&gt;
-5.026885        They know their business better than anybody . &lt;e&gt;

</code></pre>
</div>
<ul>
  <li>第一行为输入的源语言句子。</li>
  <li>第二 ~ beam_size + 1 行是柱搜索生成的 <code class="highlighter-rouge">beam_size</code> 条翻译结果
    <ul>
      <li>相同行的输出以“\t”分隔为两列，第一列是句子的log 概率，第二列是翻译结果的文本。</li>
      <li>符号<code class="highlighter-rouge">&lt;s&gt;</code> 表示句子的开始，符号<code class="highlighter-rouge">&lt;e&gt;</code>表示一个句子的结束，如果出现了在词典中未包含的词，则用符号<code class="highlighter-rouge">&lt;unk&gt;</code>替代。</li>
    </ul>
  </li>
</ul>

<p>至此，我们在 PaddlePaddle 上实现了一个初步的机器翻译模型。我们可以看到，PaddlePaddle 提供了灵活丰富的API供大家选择和使用，使得我们能够很方便完成各种复杂网络的配置。机器翻译本身也是个快速发展的领域，各种新方法新思想在不断涌现。在学习完本例后，读者若有兴趣和余力，可基于 PaddlePaddle 平台实现更为复杂、性能更优的机器翻译模型。</p>

<h2 id="参考文献">参考文献</h2>
<p>[1] Sutskever I, Vinyals O, Le Q V. <a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a>[J]. 2014, 4:3104-3112.</p>

<p>[2]Cho K, Van Merriënboer B, Gulcehre C, et al. <a href="http://www.aclweb.org/anthology/D/D14/D14-1179.pdf">Learning phrase representations using RNN encoder-decoder for statistical machine translation</a>[C]. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2014: 1724-1734.</p>

<p>[3] Bahdanau D, Cho K, Bengio Y. <a href="https://arxiv.org/abs/1409.0473">Neural machine translation by jointly learning to align and translate</a>[C]. Proceedings of ICLR 2015, 2015</p>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">PaddlePaddle Model Zoo</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              PaddlePaddle Model Zoo
            
            </li>
            
            <li><a href="mailto:idl-paddle@baidu.com">idl-paddle@baidu.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/baidu"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">baidu</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/PaddlePaddle"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">PaddlePaddle</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
