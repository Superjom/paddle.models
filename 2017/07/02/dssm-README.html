<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title> Deep Structured Semantic Models (DSSM)</title>
  <meta name="description" content="Deep Structured Semantic Models (DSSM) Deep Structured Semantic Models (DSSM) is simple but powerful DNN based model for matching web search queries and the ...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://localhost:4000/2017/07/02/dssm-README.html">
  <link rel="alternate" type="application/rss+xml" title="PaddlePaddle Model Zoo" href="/feed.xml">
  <link rel="stylesheet" href="/assets/github-markdown.css">
  
  
</head>


  <body>

    <header class="site-header" role="banner">
  <a class="site-title" href="/">
    <img src="/images/logo.png"/>
    <span style="padding-top: 7px;">Blog</span>
  </a>

  <div class="wrapper">
    
    
  
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
            <a class="page-link" href="http://www.paddlepaddle.org">Home</a>
            <a class="page-link active" href="http://models.paddlepaddle.org">Models</a>
            <a class="page-link" href="http://blog.paddlepaddle.org">Blog</a>
            <!-- <a class="page-link" href="http://blog.paddlepaddle.org">Wiki</a> -->
            <a class="page-link" href="https://github.com/PaddlePaddle/Paddle">
              <img src="/images/github.png" style="height: 15px;"/>
              Github</a>
        </div>
      </nav>

  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline"> Deep Structured Semantic Models (DSSM)</h1>
    <p class="post-meta">
      <time datetime="2017-07-02T00:00:00-07:00" itemprop="datePublished">
        
        Jul 2, 2017
      </time>
      </p>
  </header>

  <!-- <div class="post-content" itemprop="articleBody">-->
  <div class="markdown-body" itemprop="articleBody">
    <h1 id="deep-structured-semantic-models-dssm">Deep Structured Semantic Models (DSSM)</h1>
<p>Deep Structured Semantic Models (DSSM) is simple but powerful DNN based model for matching web search queries and the URL based documents. This example demonstrates how to use PaddlePaddle to implement a generic DSSM model for modeling the semantic similarity between two strings.</p>

<h2 id="background-introduction">Background Introduction</h2>
<p>DSSM [<a href="##References">1</a>]is a classic semantic model proposed by the Institute of Physics. It is used to study the semantic distance between two texts. The general implementation of DSSM is as follows.</p>

<ol>
  <li>The CTR predictor measures the degree of association between a user search query and a candidate web page.</li>
  <li>Text relevance, which measures the degree of semantic correlation between two strings.</li>
  <li>Automatically recommend, measure the degree of association between User and the recommended Item.</li>
</ol>

<h2 id="model-architecture">Model Architecture</h2>

<p>In the original paper [<a href="#References">1</a>] the DSSM model uses the implicit semantic relation between the user search query and the document as metric. The model structure is as follows</p>

<p align="center">
<img src="./images/dssm.png" /><br /><br />
Figure 1. DSSM In the original paper
</p>

<p>With the subsequent optimization of the DSSM model to simplify the structure [<a href="#References">3</a>]，the model becomes：</p>

<p align="center">
<img src="./images/dssm2.png" width="600" /><br /><br />
Figure 2. DSSM generic structure
</p>

<p>The blank box in the figure can be replaced by any model, such as fully connected FC, convoluted CNN, RNN, etc. The structure is designed to measure the semantic distance between two elements (such as strings).</p>

<p>In practice，DSSM model serves as a basic building block, with different loss functions to achieve specific functions, such as</p>

<ul>
  <li>In ranking system, the pairwise rank loss function.</li>
  <li>In the CTR estimate, instead of the binary classification on the click, use cross-entropy loss for a classification model</li>
  <li>In regression model,  the cosine similarity is used to calculate the similarity</li>
</ul>

<h2 id="model-implementation">Model Implementation</h2>
<p>At a high level, DSSM model is composed of three components: the left and right DNN, and loss function on top of them. In complex tasks, the structure of the left DNN and the light DNN can be different. In this example, we keep these two DNN structures the same. And we choose any of FC, CNN, and RNN for the DNN architecture.</p>

<p>In PaddlePaddle, the loss functions are supported for any of classification, regression, and ranking. Among them, the distance between the left and right DNN is calculated by the cosine similarity. In the classification task, the predicted distribution is calculated by softmax.</p>

<p>Here we demonstrate:</p>

<ul>
  <li>How CNN, FC do text information extraction can refer to <a href="https://github.com/PaddlePaddle/models/blob/develop/text_classification/README.md#模型详解">text classification</a></li>
  <li>The contents of the RNN / GRU can be found in  <a href="https://github.com/PaddlePaddle/book/blob/develop/08.machine_translation/README.md#gated-recurrent-unit-gru">Machine Translation</a></li>
  <li>For Pairwise Rank learning, please refer to <a href="https://github.com/PaddlePaddle/models/blob/develop/ltr/README.md">learn to rank</a></li>
</ul>

<p>Figure 3 shows the general architecture for both regression and classification models.</p>

<p align="center">
<img src="./images/dssm3.jpg" /><br /><br />
Figure 3. DSSM for REGRESSION or CLASSIFICATION
</p>

<p>The structure of the Pairwise Rank is more complex, as shown in Figure 4.</p>

<p align="center">
<img src="./images/dssm2.jpg" /><br /><br />
图 4. DSSM for Pairwise Rank
</p>

<p>In below, we describe how to train DSSM model in PaddlePaddle. All the codes are included in  <code class="highlighter-rouge">./network_conf.py</code>.</p>

<h3 id="create-a-word-vector-table-for-the-text">Create a word vector table for the text</h3>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="s">'''
    Create an embedding table whose name has a `prefix`.
    '''</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"create embedding table [</span><span class="si">%</span><span class="s">s] which dimention is </span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span>
                <span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">param_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'</span><span class="si">%</span><span class="s">s_emb.w'</span> <span class="o">%</span> <span class="n">prefix</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">emb</span>
</code></pre>
</div>

<p>Since the input (embedding table) is a list of the IDs of the words corresponding to a sentence, the word vector table outputs the sequence of word vectors.</p>

<h3 id="cnn-implementation">CNN implementation</h3>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_cnn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="s">'''
    A multi-layer CNN.

    @emb: paddle.layer
        output of the embedding layer
    @prefix: str
        prefix of layers' names, used to share parameters between more than one `cnn` parts.
    '''</span>
    <span class="k">def</span> <span class="nf">create_conv</span><span class="p">(</span><span class="n">context_len</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">prefix</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="s">"</span><span class="si">%</span><span class="s">s_</span><span class="si">%</span><span class="s">d_</span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span> <span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">context_len</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">conv</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">sequence_conv_pool</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="n">emb</span><span class="p">,</span>
            <span class="n">context_len</span><span class="o">=</span><span class="n">context_len</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="c"># set parameter attr for parameter sharing</span>
            <span class="n">context_proj_param_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">key</span> <span class="o">+</span> <span class="s">'contex_proj.w'</span><span class="p">),</span>
            <span class="n">fc_param_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">key</span> <span class="o">+</span> <span class="s">'_fc.w'</span><span class="p">),</span>
            <span class="n">fc_bias_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">key</span> <span class="o">+</span> <span class="s">'_fc.b'</span><span class="p">),</span>
            <span class="n">pool_bias_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">key</span> <span class="o">+</span> <span class="s">'_pool.b'</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">conv</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">'create a sequence_conv_pool which context width is 3'</span><span class="p">)</span>
    <span class="n">conv_3</span> <span class="o">=</span> <span class="n">create_conv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"cnn"</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">'create a sequence_conv_pool which context width is 4'</span><span class="p">)</span>
    <span class="n">conv_4</span> <span class="o">=</span> <span class="n">create_conv</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"cnn"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">conv_3</span><span class="p">,</span> <span class="n">conv_4</span>
</code></pre>
</div>

<p>CNN accepts the word sequence of the embedding table, then process the data by convolution and pooling, and finally outputs a semantic vector.</p>

<h3 id="rnn-implementation">RNN implementation</h3>

<p>RNN is suitable for learning variable length of the information</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_rnn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="s">'''
    A GRU sentence vector learner.
    '''</span>
    <span class="n">gru</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">gru_memory</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">emb</span><span class="p">,)</span>
    <span class="n">sent_vec</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">last_seq</span><span class="p">(</span><span class="n">gru</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sent_vec</span>
</code></pre>
</div>

<h3 id="fc-implementation">FC implementation</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_fc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="s">'''
    A multi-layer fully connected neural networks.

    @emb: paddle.layer
        output of the embedding layer
    @prefix: str
        prefix of layers' names, used to share parameters between more than one `fc` parts.
    '''</span>
    <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">pooling</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">emb</span><span class="p">,</span> <span class="n">pooling_type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">pooling</span><span class="o">.</span><span class="n">Max</span><span class="p">())</span>
    <span class="n">fc</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">_input_layer</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">fc</span>
</code></pre>
</div>

<p>In the construction of FC, we use <code class="highlighter-rouge">paddle.layer.pooling</code> for the maximum pooling operation on the word vector sequence. Then we transform the sequence into a fixed dimensional vector.</p>

<h3 id="multi-layer-dnn-implementation">Multi-layer DNN implementation</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_dnn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sent_vec</span><span class="p">,</span> <span class="n">prefix</span><span class="p">):</span>
    <span class="c"># if more than three layers exists, a fc layer will be added.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">sent_vec</span>
        <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s">"</span><span class="si">%</span><span class="s">s_fc_</span><span class="si">%</span><span class="s">d_</span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span> <span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="nb">id</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"create fc layer [</span><span class="si">%</span><span class="s">s] which dimention is </span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span>
                        <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
            <span class="n">fc</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
                <span class="nb">input</span><span class="o">=</span><span class="n">_input_layer</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
                <span class="n">param_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'</span><span class="si">%</span><span class="s">s.w'</span> <span class="o">%</span> <span class="n">name</span><span class="p">),</span>
                <span class="n">bias_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'</span><span class="si">%</span><span class="s">s.b'</span> <span class="o">%</span> <span class="n">name</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">fc</span>
    <span class="k">return</span> <span class="n">_input_layer</span>
</code></pre>
</div>

<h3 id="classification--regression">Classification / Regression</h3>
<p>The structure of classification and regression is similar. Below function can be used for both tasks.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_build_classification_or_regression_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_classification</span><span class="p">):</span>
    <span class="s">'''
    Build a classification/regression model, and the cost is returned.

    A Classification has 3 inputs:
      - source sentence
      - target sentence
      - classification label

    '''</span>
    <span class="c"># prepare inputs.</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_num</span>

    <span class="n">source</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'source_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'target_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'label_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_classification</span> <span class="k">else</span> <span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">dense_input</span><span class="p">)</span>

    <span class="n">prefixs</span> <span class="o">=</span> <span class="s">'_ _'</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
    <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">share_semantic_generator</span> <span class="k">else</span> <span class="s">'left right'</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">embed_prefixs</span> <span class="o">=</span> <span class="s">'_ _'</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
    <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">share_embed</span> <span class="k">else</span> <span class="s">'left right'</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="n">word_vecs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">]):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">embed_prefixs</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">word_vecs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">semantics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_vecs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_arch_creater</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefixs</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">semantics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">concated_vector</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">semantics</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">concated_vector</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_num</span><span class="p">,</span>
        <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Softmax</span><span class="p">())</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">classification_cost</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">prediction</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_classification</span> <span class="k">else</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">mse_cost</span><span class="p">(</span>
            <span class="n">prediction</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cost</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">label</span>
</code></pre>
</div>

<h3 id="pairwise-rank">Pairwise Rank</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_build_rank_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s">'''
    Build a pairwise rank model, and the cost is returned.

    A pairwise rank model has 3 inputs:
      - source sentence
      - left_target sentence
      - right_target sentence
      - label, 1 if left_target should be sorted in front of right_target, otherwise 0.
    '''</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'source_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">left_target</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'left_target_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">right_target</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'right_target_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'label_input'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">prefixs</span> <span class="o">=</span> <span class="s">'_ _ _'</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
    <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">share_semantic_generator</span> <span class="k">else</span> <span class="s">'source left right'</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">embed_prefixs</span> <span class="o">=</span> <span class="s">'_ _'</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
    <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">share_embed</span> <span class="k">else</span> <span class="s">'source target target'</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="n">word_vecs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">source</span><span class="p">,</span> <span class="n">left_target</span><span class="p">,</span> <span class="n">right_target</span><span class="p">]):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">embed_prefixs</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">word_vecs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">semantics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_vecs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_arch_creater</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefixs</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">semantics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c"># cossim score of source and left_target</span>
    <span class="n">left_score</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">cos_sim</span><span class="p">(</span><span class="n">semantics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">semantics</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="c"># cossim score of source and right target</span>
    <span class="n">right_score</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">cos_sim</span><span class="p">(</span><span class="n">semantics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">semantics</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

    <span class="c"># rank cost</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">rank_cost</span><span class="p">(</span><span class="n">left_score</span><span class="p">,</span> <span class="n">right_score</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="c"># prediction = left_score - right_score</span>
    <span class="c"># but this operator is not supported currently.</span>
    <span class="c"># so AUC will not used.</span>
    <span class="k">return</span> <span class="n">cost</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
</code></pre>
</div>
<h2 id="data-format">Data Format</h2>
<p>Below is a simple example for the data in <code class="highlighter-rouge">./data</code></p>

<h3 id="regression-data-format">Regression data format</h3>
<div class="highlighter-rouge"><pre class="highlight"><code># 3 fields each line:
#   - source's word ids
#   - target's word ids
#   - target
&lt;ids&gt; \t &lt;ids&gt; \t &lt;float&gt;
</code></pre>
</div>

<p>The example of this format is as follows.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>3 6 10 \t 6 8 33 \t 0.7
6 0 \t 6 9 330 \t 0.03
</code></pre>
</div>

<h3 id="classification-data-format">Classification data format</h3>
<div class="highlighter-rouge"><pre class="highlight"><code># 3 fields each line:
#   - source's word ids
#   - target's word ids
#   - target
&lt;ids&gt; \t &lt;ids&gt; \t &lt;label&gt;
</code></pre>
</div>

<p>The example of this format is as follows.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>3 6 10 \t 6 8 33 \t 0
6 10 \t 8 3 1 \t 1
</code></pre>
</div>

<h3 id="ranking-data-format">Ranking data format</h3>
<div class="highlighter-rouge"><pre class="highlight"><code># 4 fields each line:
#   - source's word ids
#   - target1's word ids
#   - target2's word ids
#   - label
&lt;ids&gt; \t &lt;ids&gt; \t &lt;ids&gt; \t &lt;label&gt;
</code></pre>
</div>

<p>The example of this format is as follows.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>7 2 4 \t 2 10 12 \t 9 2 7 10 23 \t 0
7 2 4 \t 10 12 \t 9 2 21 23 \t 1
</code></pre>
</div>

<h2 id="training">Training</h2>

<p>We use <code class="highlighter-rouge">python train.py -y 0 --model_arch 0</code> with the data in  <code class="highlighter-rouge">./data/classification</code> to train a DSSM model for classification.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>usage: train.py [-h] [-i TRAIN_DATA_PATH] [-t TEST_DATA_PATH]
                [-s SOURCE_DIC_PATH] [--target_dic_path TARGET_DIC_PATH]
                [-b BATCH_SIZE] [-p NUM_PASSES] -y MODEL_TYPE -a MODEL_ARCH
                [--share_network_between_source_target SHARE_NETWORK_BETWEEN_SOURCE_TARGET]
                [--share_embed SHARE_EMBED] [--dnn_dims DNN_DIMS]
                [--num_workers NUM_WORKERS] [--use_gpu USE_GPU] [-c CLASS_NUM]
                [--model_output_prefix MODEL_OUTPUT_PREFIX]
                [-g NUM_BATCHES_TO_LOG] [-e NUM_BATCHES_TO_TEST]
                [-z NUM_BATCHES_TO_SAVE_MODEL]

PaddlePaddle DSSM example

optional arguments:
  -h, --help            show this help message and exit
  -i TRAIN_DATA_PATH, --train_data_path TRAIN_DATA_PATH
                        path of training dataset
  -t TEST_DATA_PATH, --test_data_path TEST_DATA_PATH
                        path of testing dataset
  -s SOURCE_DIC_PATH, --source_dic_path SOURCE_DIC_PATH
                        path of the source's word dic
  --target_dic_path TARGET_DIC_PATH
                        path of the target's word dic, if not set, the
                        `source_dic_path` will be used
  -b BATCH_SIZE, --batch_size BATCH_SIZE
                        size of mini-batch (default:10)
  -p NUM_PASSES, --num_passes NUM_PASSES
                        number of passes to run(default:10)
  -y MODEL_TYPE, --model_type MODEL_TYPE
                        model type, 0 for classification, 1 for pairwise rank,
                        2 for regression (default: classification)
  -a MODEL_ARCH, --model_arch MODEL_ARCH
                        model architecture, 1 for CNN, 0 for FC, 2 for RNN
  --share_network_between_source_target SHARE_NETWORK_BETWEEN_SOURCE_TARGET
                        whether to share network parameters between source and
                        target
  --share_embed SHARE_EMBED
                        whether to share word embedding between source and
                        target
  --dnn_dims DNN_DIMS   dimentions of dnn layers, default is '256,128,64,32',
                        which means create a 4-layer dnn, demention of each
                        layer is 256, 128, 64 and 32
  --num_workers NUM_WORKERS
                        num worker threads, default 1
  --use_gpu USE_GPU     whether to use GPU devices (default: False)
  -c CLASS_NUM, --class_num CLASS_NUM
                        number of categories for classification task.
  --model_output_prefix MODEL_OUTPUT_PREFIX
                        prefix of the path for model to store, (default: ./)
  -g NUM_BATCHES_TO_LOG, --num_batches_to_log NUM_BATCHES_TO_LOG
                        number of batches to output train log, (default: 100)
  -e NUM_BATCHES_TO_TEST, --num_batches_to_test NUM_BATCHES_TO_TEST
                        number of batches to test, (default: 200)
  -z NUM_BATCHES_TO_SAVE_MODEL, --num_batches_to_save_model NUM_BATCHES_TO_SAVE_MODEL
                        number of batches to output model, (default: 400)
</code></pre>
</div>

<p>Parameter description:</p>

<ul>
  <li><code class="highlighter-rouge">train_data_path</code> Training data path</li>
  <li><code class="highlighter-rouge">test_data_path</code>  Test data path, optional</li>
  <li><code class="highlighter-rouge">source_dic_path</code>  Source dictionary path</li>
  <li><code class="highlighter-rouge">target_dic_path</code> 目Target dictionary path</li>
  <li><code class="highlighter-rouge">model_type</code>  The type of loss function of the model: classification 0, sort 1, regression 2</li>
  <li><code class="highlighter-rouge">model_arch</code> Model structure: FC 0，CNN 1, RNN 2</li>
  <li><code class="highlighter-rouge">dnn_dims</code> The dimension of each layer of the model is set, the default is <code class="highlighter-rouge">256,128,64,32</code>，with 4 layers.</li>
</ul>

<h2 id="to-predict-using-the-trained-model">To predict using the trained model</h2>
<div class="highlighter-rouge"><pre class="highlight"><code>usage: infer.py [-h] --model_path MODEL_PATH -i DATA_PATH -o
                PREDICTION_OUTPUT_PATH -y MODEL_TYPE [-s SOURCE_DIC_PATH]
                [--target_dic_path TARGET_DIC_PATH] -a MODEL_ARCH
                [--share_network_between_source_target SHARE_NETWORK_BETWEEN_SOURCE_TARGET]
                [--share_embed SHARE_EMBED] [--dnn_dims DNN_DIMS]
                [-c CLASS_NUM]

PaddlePaddle DSSM infer

optional arguments:
  -h, --help            show this help message and exit
  --model_path MODEL_PATH
                        path of model parameters file
  -i DATA_PATH, --data_path DATA_PATH
                        path of the dataset to infer
  -o PREDICTION_OUTPUT_PATH, --prediction_output_path PREDICTION_OUTPUT_PATH
                        path to output the prediction
  -y MODEL_TYPE, --model_type MODEL_TYPE
                        model type, 0 for classification, 1 for pairwise rank,
                        2 for regression (default: classification)
  -s SOURCE_DIC_PATH, --source_dic_path SOURCE_DIC_PATH
                        path of the source's word dic
  --target_dic_path TARGET_DIC_PATH
                        path of the target's word dic, if not set, the
                        `source_dic_path` will be used
  -a MODEL_ARCH, --model_arch MODEL_ARCH
                        model architecture, 1 for CNN, 0 for FC, 2 for RNN
  --share_network_between_source_target SHARE_NETWORK_BETWEEN_SOURCE_TARGET
                        whether to share network parameters between source and
                        target
  --share_embed SHARE_EMBED
                        whether to share word embedding between source and
                        target
  --dnn_dims DNN_DIMS   dimentions of dnn layers, default is '256,128,64,32',
                        which means create a 4-layer dnn, demention of each
                        layer is 256, 128, 64 and 32
  -c CLASS_NUM, --class_num CLASS_NUM
                        number of categories for classification task.
</code></pre>
</div>

<p>Important parameters are</p>

<ul>
  <li><code class="highlighter-rouge">data_path</code> Path for the data to predict</li>
  <li><code class="highlighter-rouge">prediction_output_path</code> Prediction output path</li>
</ul>

<h2 id="references">References</h2>

<ol>
  <li>Huang P S, He X, Gao J, et al. Learning deep structured semantic models for web search using clickthrough data[C]//Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management. ACM, 2013: 2333-2338.</li>
  <li><a href="https://www.microsoft.com/en-us/research/project/mslr/">Microsoft Learning to Rank Datasets</a></li>
  <li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/wsdm2015.v3.pdf">Gao J, He X, Deng L. Deep Learning for Web Search and Natural Language Processing[J]. Microsoft Research Technical Report, 2015.</a></li>
</ol>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">PaddlePaddle Model Zoo</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              PaddlePaddle Model Zoo
            
            </li>
            
            <li><a href="mailto:idl-paddle@baidu.com">idl-paddle@baidu.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/PaddlePaddle"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">PaddlePaddle</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/BaiduResearch"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">BaiduResearch</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>PaddlePaddle, PArallel Distributed Deep LEarning, n Easy-to-use, Efficient, Flexible and Scalable Deep Learning Platform.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
