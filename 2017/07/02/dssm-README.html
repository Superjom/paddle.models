<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title> 深度结构化语义模型 (Deep Structured Semantic Models, DSSM)</title>
  <meta name="description" content="深度结构化语义模型 (Deep Structured Semantic Models, DSSM) DSSM使用DNN模型在一个连续的语义空间中学习文本低纬的表示向量，并且建模两个句子间的语义相似度。 本例演示如何使用 PaddlePaddle实现一个通用的DSSM 模型，用于建模两个字符串间的语义相似度， 模型...">

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="http://models.paddlepaddle.org/2017/07/02/dssm-README.html">
  <link rel="alternate" type="application/rss+xml" title="PaddlePaddle Model Zoo" href="/feed.xml">
  
  
</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" href="/">PaddlePaddle Model Zoo</a>
  
    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            
          
            
            
          
            
            
          
            
            
          
            
            
          
            
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline"> 深度结构化语义模型 (Deep Structured Semantic Models, DSSM)</h1>
    <p class="post-meta">
      <time datetime="2017-07-02T00:00:00+08:00" itemprop="datePublished">
        
        Jul 2, 2017
      </time>
      </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h1 id="深度结构化语义模型-deep-structured-semantic-models-dssm">深度结构化语义模型 (Deep Structured Semantic Models, DSSM)</h1>
<p>DSSM使用DNN模型在一个连续的语义空间中学习文本低纬的表示向量，并且建模两个句子间的语义相似度。
本例演示如何使用 PaddlePaddle实现一个通用的DSSM 模型，用于建模两个字符串间的语义相似度，
模型实现支持通用的数据格式，用户替换数据便可以在真实场景中使用该模型。</p>

<h2 id="背景介绍">背景介绍</h2>
<p>DSSM [<a href="##参考文献">1</a>]是微软研究院13年提出来的经典的语义模型，用于学习两个文本之间的语义距离，
广义上模型也可以推广和适用如下场景：</p>

<ol>
  <li>CTR预估模型，衡量用户搜索词（Query）与候选网页集合（Documents）之间的相关联程度。</li>
  <li>文本相关性，衡量两个字符串间的语义相关程度。</li>
  <li>自动推荐，衡量User与被推荐的Item之间的关联程度。</li>
</ol>

<p>DSSM 已经发展成了一个框架，可以很自然地建模两个记录之间的距离关系，
例如对于文本相关性问题，可以用余弦相似度 (cosin similarity) 来刻画语义距离；
而对于搜索引擎的结果排序，可以在DSSM上接上Rank损失训练处一个排序模型。</p>

<h2 id="模型简介">模型简介</h2>
<p>在原论文[<a href="#参考文献">1</a>]中，DSSM模型用来衡量用户搜索词 Query 和文档集合 Documents 之间隐含的语义关系，模型结构如下</p>

<p align="center">
<img src="./images/dssm.png" /><br /><br />
图 1. DSSM 原始结构
</p>

<p>其贯彻的思想是， <strong>用DNN将高维特征向量转化为低纬空间的连续向量（图中红色框部分）</strong> ，
<strong>在上层用cosin similarity来衡量用户搜索词与候选文档间的语义相关性</strong> 。</p>

<p>在最顶层损失函数的设计上，原始模型使用类似Word2Vec中负例采样的方法，
一个Query会抽取正例 $D+$ 和4个负例 $D-$ 整体上算条件概率用对数似然函数作为损失，
这也就是图 1中类似 $P(D_1|Q)$ 的结构，具体细节请参考原论文。</p>

<p>随着后续优化DSSM模型的结构得以简化[<a href="#参考文献">3</a>]，演变为：</p>

<p align="center">
<img src="./images/dssm2.png" width="600" /><br /><br />
图 2. DSSM通用结构
</p>

<p>图中的空白方框可以用任何模型替代，比如全连接FC，卷积CNN，RNN等都可以，
该模型结构专门用于衡量两个元素（比如字符串）间的语义距离。</p>

<p>在现实使用中，DSSM模型会作为基础的积木，搭配上不同的损失函数来实现具体的功能，比如</p>

<ul>
  <li>在排序学习中，将 图 2 中结构添加 pairwise rank损失，变成一个排序模型</li>
  <li>在CTR预估中，对点击与否做0，1二元分类，添加交叉熵损失变成一个分类模型</li>
  <li>在需要对一个子串打分时，可以使用余弦相似度来计算相似度，变成一个回归模型</li>
</ul>

<p>本例将尝试面向应用提供一个比较通用的解决方案，在模型任务类型上支持</p>

<ul>
  <li>分类</li>
  <li>[-1, 1] 值域内的回归</li>
  <li>Pairwise-Rank</li>
</ul>

<p>在生成低纬语义向量的模型结构上，本模型支持以下三种：</p>

<ul>
  <li>FC, 多层全连接层</li>
  <li>CNN，卷积神经网络</li>
  <li>RNN，递归神经网络</li>
</ul>

<h2 id="模型实现">模型实现</h2>
<p>DSSM模型可以拆成三小块实现，分别是左边和右边的DNN，以及顶层的损失函数。
在复杂任务中，左右两边DNN的结构可以是不同的，比如在原始论文中左右分别学习Query和Document的semantic vector，
两者数据的数据不同，建议对应定制DNN的结构。</p>

<p>本例中为了简便和通用，将左右两个DNN的结构都设为相同的，因此只有三个选项FC,CNN,RNN等。</p>

<p>在损失函数的设计方面，也支持三种，分类, 回归, 排序；
其中，在回归和排序两种损失中，左右两边的匹配程度通过余弦相似度（cossim）来计算；
在分类任务中，类别预测的分布通过softmax计算。</p>

<p>在其它教程中，对上述很多内容都有过详细的介绍，例如：</p>

<ul>
  <li>如何CNN, FC 做文本信息提取可以参考 <a href="https://github.com/PaddlePaddle/models/blob/develop/text_classification/README.md#模型详解">text classification</a></li>
  <li>RNN/GRU 的内容可以参考 <a href="https://github.com/PaddlePaddle/book/blob/develop/08.machine_translation/README.md#gated-recurrent-unit-gru">Machine Translation</a></li>
  <li>Pairwise Rank即排序学习可参考 <a href="https://github.com/PaddlePaddle/models/blob/develop/ltr/README.md">learn to rank</a></li>
</ul>

<p>相关原理在此不再赘述，本文接下来的篇幅主要集中介绍使用PaddlePaddle实现这些结构上。</p>

<p>如图3，回归和分类模型的结构很相似</p>

<p align="center">
<img src="./images/dssm3.jpg" /><br /><br />
图 3. DSSM for REGRESSION or CLASSIFICATION
</p>

<p>最重要的组成部分包括词向量，图中<code class="highlighter-rouge">(1)</code>,<code class="highlighter-rouge">(2)</code>两个低纬向量的学习器（可以用RNN/CNN/FC中的任意一种实现），
最上层对应的损失函数。</p>

<p>而Pairwise Rank的结构会复杂一些，类似两个 图 4. 中的结构，增加了对应的损失函数：</p>

<ul>
  <li>模型总体思想是，用同一个source(源)为左右两个target(目标)分别打分——<code class="highlighter-rouge">(a),(b)</code>，学习目标是(a),(b)间的大小关系</li>
  <li><code class="highlighter-rouge">(a)</code>和<code class="highlighter-rouge">(b)</code>类似图3中结构，用于给source和target的pair打分</li>
  <li><code class="highlighter-rouge">(1)</code>和<code class="highlighter-rouge">(2)</code>的结构其实是共用的，都表示同一个source，图中为了表达效果展开成两个</li>
</ul>

<p align="center">
<img src="./images/dssm2.jpg" /><br /><br />
图 4. DSSM for Pairwise Rank
</p>

<p>下面是各个部分具体的实现方法，所有的代码均包含在 <code class="highlighter-rouge">./network_conf.py</code> 中。</p>

<h3 id="创建文本的词向量表">创建文本的词向量表</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="s">'''
    Create an embedding table whose name has a `prefix`.
    '''</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"create embedding table [</span><span class="si">%</span><span class="s">s] which dimention is </span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span>
                <span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">param_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'</span><span class="si">%</span><span class="s">s_emb.w'</span> <span class="o">%</span> <span class="n">prefix</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">emb</span>
</code></pre>
</div>

<p>由于输入给词向量表(embedding table)的是一个句子对应的词的ID的列表 ，因此词向量表输出的是词向量的序列。</p>

<h3 id="cnn-结构实现">CNN 结构实现</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_cnn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="s">'''
    A multi-layer CNN.

    @emb: paddle.layer
        output of the embedding layer
    @prefix: str
        prefix of layers' names, used to share parameters between more than one `cnn` parts.
    '''</span>
    <span class="k">def</span> <span class="nf">create_conv</span><span class="p">(</span><span class="n">context_len</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">prefix</span><span class="p">):</span>
        <span class="n">key</span> <span class="o">=</span> <span class="s">"</span><span class="si">%</span><span class="s">s_</span><span class="si">%</span><span class="s">d_</span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span> <span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">context_len</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
        <span class="n">conv</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">sequence_conv_pool</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="n">emb</span><span class="p">,</span>
            <span class="n">context_len</span><span class="o">=</span><span class="n">context_len</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="c"># set parameter attr for parameter sharing</span>
            <span class="n">context_proj_param_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">key</span> <span class="o">+</span> <span class="s">'contex_proj.w'</span><span class="p">),</span>
            <span class="n">fc_param_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">key</span> <span class="o">+</span> <span class="s">'_fc.w'</span><span class="p">),</span>
            <span class="n">fc_bias_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">key</span> <span class="o">+</span> <span class="s">'_fc.b'</span><span class="p">),</span>
            <span class="n">pool_bias_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">key</span> <span class="o">+</span> <span class="s">'_pool.b'</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">conv</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">'create a sequence_conv_pool which context width is 3'</span><span class="p">)</span>
    <span class="n">conv_3</span> <span class="o">=</span> <span class="n">create_conv</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"cnn"</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">'create a sequence_conv_pool which context width is 4'</span><span class="p">)</span>
    <span class="n">conv_4</span> <span class="o">=</span> <span class="n">create_conv</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">"cnn"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">conv_3</span><span class="p">,</span> <span class="n">conv_4</span>
</code></pre>
</div>

<p>CNN 接受 embedding table输出的词向量序列，通过卷积和池化操作捕捉到原始句子的关键信息，
最终输出一个语义向量（可以认为是句子向量）。</p>

<p>本例的实现中，分别使用了窗口长度为3和4的CNN学到的句子向量按元素求和得到最终的句子向量。</p>

<h3 id="rnn-结构实现">RNN 结构实现</h3>

<p>RNN很适合学习变长序列的信息，使用RNN来学习句子的信息几乎是自然语言处理任务的标配。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_rnn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="s">'''
    A GRU sentence vector learner.
    '''</span>
    <span class="n">gru</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">gru_memory</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">emb</span><span class="p">,)</span>
    <span class="n">sent_vec</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">last_seq</span><span class="p">(</span><span class="n">gru</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sent_vec</span>
</code></pre>
</div>

<h3 id="fc-结构实现">FC 结构实现</h3>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_fc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">emb</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s">''</span><span class="p">):</span>
    <span class="s">'''
    A multi-layer fully connected neural networks.

    @emb: paddle.layer
        output of the embedding layer
    @prefix: str
        prefix of layers' names, used to share parameters between more than one `fc` parts.
    '''</span>
    <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">pooling</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">emb</span><span class="p">,</span> <span class="n">pooling_type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">pooling</span><span class="o">.</span><span class="n">Max</span><span class="p">())</span>
    <span class="n">fc</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">_input_layer</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">fc</span>
</code></pre>
</div>

<p>在构建FC时需要首先使用<code class="highlighter-rouge">paddle.layer.pooling</code> 对词向量序列进行最大池化操作，将边长序列转化为一个固定维度向量，
作为整个句子的语义表达，使用最大池化能够降低句子长度对句向量表达的影响。</p>

<h3 id="多层dnn实现">多层DNN实现</h3>
<p>在 CNN/DNN/FC提取出 semantic vector后，在上层可继续接多层FC来实现深层DNN结构。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_dnn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sent_vec</span><span class="p">,</span> <span class="n">prefix</span><span class="p">):</span>
    <span class="c"># if more than three layers exists, a fc layer will be added.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">sent_vec</span>
        <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="s">"</span><span class="si">%</span><span class="s">s_fc_</span><span class="si">%</span><span class="s">d_</span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span> <span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="nb">id</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s">"create fc layer [</span><span class="si">%</span><span class="s">s] which dimention is </span><span class="si">%</span><span class="s">d"</span> <span class="o">%</span>
                        <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
            <span class="n">fc</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
                <span class="nb">input</span><span class="o">=</span><span class="n">_input_layer</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
                <span class="n">param_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'</span><span class="si">%</span><span class="s">s.w'</span> <span class="o">%</span> <span class="n">name</span><span class="p">),</span>
                <span class="n">bias_attr</span><span class="o">=</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">'</span><span class="si">%</span><span class="s">s.b'</span> <span class="o">%</span> <span class="n">name</span><span class="p">),</span>
                <span class="p">)</span>
            <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">fc</span>
    <span class="k">return</span> <span class="n">_input_layer</span>
</code></pre>
</div>

<h3 id="分类或回归实现">分类或回归实现</h3>
<p>分类和回归的结构比较相似，因此可以用一个函数创建出来</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_build_classification_or_regression_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">is_classification</span><span class="p">):</span>
    <span class="s">'''
    Build a classification/regression model, and the cost is returned.

    A Classification has 3 inputs:
      - source sentence
      - target sentence
      - classification label

    '''</span>
    <span class="c"># prepare inputs.</span>
    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_num</span>

    <span class="n">source</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'source_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">target</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'target_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'label_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">class_num</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_classification</span> <span class="k">else</span> <span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">dense_input</span><span class="p">)</span>

    <span class="n">prefixs</span> <span class="o">=</span> <span class="s">'_ _'</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
    <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">share_semantic_generator</span> <span class="k">else</span> <span class="s">'left right'</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">embed_prefixs</span> <span class="o">=</span> <span class="s">'_ _'</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
    <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">share_embed</span> <span class="k">else</span> <span class="s">'left right'</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="n">word_vecs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">]):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">embed_prefixs</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">word_vecs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">semantics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_vecs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_arch_creater</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefixs</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">semantics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">concated_vector</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">semantics</span><span class="p">)</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">concated_vector</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">class_num</span><span class="p">,</span>
        <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Softmax</span><span class="p">())</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">classification_cost</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">prediction</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span> <span class="k">if</span> <span class="n">is_classification</span> <span class="k">else</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">mse_cost</span><span class="p">(</span>
            <span class="n">prediction</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cost</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">label</span>
</code></pre>
</div>
<h3 id="pairwise-rank实现">Pairwise Rank实现</h3>
<p>Pairwise Rank复用上面的DNN结构，同一个source对两个target求相似度打分，
如果左边的target打分高，预测为1，否则预测为 0。</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_build_rank_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="s">'''
    Build a pairwise rank model, and the cost is returned.

    A pairwise rank model has 3 inputs:
      - source sentence
      - left_target sentence
      - right_target sentence
      - label, 1 if left_target should be sorted in front of right_target, otherwise 0.
    '''</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'source_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">left_target</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'left_target_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">right_target</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'right_target_input'</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value_sequence</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s">'label_input'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">prefixs</span> <span class="o">=</span> <span class="s">'_ _ _'</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
    <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">share_semantic_generator</span> <span class="k">else</span> <span class="s">'source left right'</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">embed_prefixs</span> <span class="o">=</span> <span class="s">'_ _'</span><span class="o">.</span><span class="n">split</span><span class="p">(</span>
    <span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">share_embed</span> <span class="k">else</span> <span class="s">'source target target'</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="n">word_vecs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">source</span><span class="p">,</span> <span class="n">left_target</span><span class="p">,</span> <span class="n">right_target</span><span class="p">]):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">embed_prefixs</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">word_vecs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="n">semantics</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="nb">input</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_vecs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_arch_creater</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefixs</span><span class="p">[</span><span class="nb">id</span><span class="p">])</span>
        <span class="n">semantics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c"># cossim score of source and left_target</span>
    <span class="n">left_score</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">cos_sim</span><span class="p">(</span><span class="n">semantics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">semantics</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="c"># cossim score of source and right target</span>
    <span class="n">right_score</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">cos_sim</span><span class="p">(</span><span class="n">semantics</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">semantics</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

    <span class="c"># rank cost</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">rank_cost</span><span class="p">(</span><span class="n">left_score</span><span class="p">,</span> <span class="n">right_score</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="c"># prediction = left_score - right_score</span>
    <span class="c"># but this operator is not supported currently.</span>
    <span class="c"># so AUC will not used.</span>
    <span class="k">return</span> <span class="n">cost</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span>
</code></pre>
</div>
<h2 id="数据格式">数据格式</h2>
<p>在 <code class="highlighter-rouge">./data</code> 中有简单的示例数据</p>

<h3 id="回归的数据格式">回归的数据格式</h3>
<div class="highlighter-rouge"><pre class="highlight"><code># 3 fields each line:
#   - source's word ids
#   - target's word ids
#   - target
&lt;ids&gt; \t &lt;ids&gt; \t &lt;float&gt;
</code></pre>
</div>

<p>比如：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>3 6 10 \t 6 8 33 \t 0.7
6 0 \t 6 9 330 \t 0.03
</code></pre>
</div>
<h3 id="分类的数据格式">分类的数据格式</h3>
<div class="highlighter-rouge"><pre class="highlight"><code># 3 fields each line:
#   - source's word ids
#   - target's word ids
#   - target
&lt;ids&gt; \t &lt;ids&gt; \t &lt;label&gt;
</code></pre>
</div>

<p>比如：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>3 6 10 \t 6 8 33 \t 0
6 10 \t 8 3 1 \t 1
</code></pre>
</div>

<h3 id="排序的数据格式">排序的数据格式</h3>
<div class="highlighter-rouge"><pre class="highlight"><code># 4 fields each line:
#   - source's word ids
#   - target1's word ids
#   - target2's word ids
#   - label
&lt;ids&gt; \t &lt;ids&gt; \t &lt;ids&gt; \t &lt;label&gt;
</code></pre>
</div>

<p>比如：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>7 2 4 \t 2 10 12 \t 9 2 7 10 23 \t 0
7 2 4 \t 10 12 \t 9 2 21 23 \t 1
</code></pre>
</div>

<h2 id="执行训练">执行训练</h2>

<p>可以直接执行 <code class="highlighter-rouge">python train.py -y 0 --model_arch 0</code> 使用 <code class="highlighter-rouge">./data/classification</code> 目录里简单的数据来训练一个分类的FC模型。</p>

<p>其他模型结构也可以通过命令行实现定制，详细命令行参数如下</p>

<div class="highlighter-rouge"><pre class="highlight"><code>usage: train.py [-h] [-i TRAIN_DATA_PATH] [-t TEST_DATA_PATH]
                [-s SOURCE_DIC_PATH] [--target_dic_path TARGET_DIC_PATH]
                [-b BATCH_SIZE] [-p NUM_PASSES] -y MODEL_TYPE --model_arch
                MODEL_ARCH
                [--share_network_between_source_target SHARE_NETWORK_BETWEEN_SOURCE_TARGET]
                [--share_embed SHARE_EMBED] [--dnn_dims DNN_DIMS]
                [--num_workers NUM_WORKERS] [--use_gpu USE_GPU] [-c CLASS_NUM]

PaddlePaddle DSSM example

optional arguments:
  -h, --help            show this help message and exit
  -i TRAIN_DATA_PATH, --train_data_path TRAIN_DATA_PATH
                        path of training dataset
  -t TEST_DATA_PATH, --test_data_path TEST_DATA_PATH
                        path of testing dataset
  -s SOURCE_DIC_PATH, --source_dic_path SOURCE_DIC_PATH
                        path of the source's word dic
  --target_dic_path TARGET_DIC_PATH
                        path of the target's word dic, if not set, the
                        `source_dic_path` will be used
  -b BATCH_SIZE, --batch_size BATCH_SIZE
                        size of mini-batch (default:10)
  -p NUM_PASSES, --num_passes NUM_PASSES
                        number of passes to run(default:10)
  -y MODEL_TYPE, --model_type MODEL_TYPE
                        model type, 0 for classification, 1 for pairwise rank
                        (default: classification)
  --model_arch MODEL_ARCH
                        model architecture, 1 for CNN, 0 for FC, 2 for RNN
  --share_network_between_source_target SHARE_NETWORK_BETWEEN_SOURCE_TARGET
                        whether to share network parameters between source and
                        target
  --share_embed SHARE_EMBED
                        whether to share word embedding between source and
                        target
  --dnn_dims DNN_DIMS   dimentions of dnn layers, default is '256,128,64,32',
                        which means create a 4-layer dnn, demention of each
                        layer is 256, 128, 64 and 32
  --num_workers NUM_WORKERS
                        num worker threads, default 1
  --use_gpu USE_GPU     whether to use GPU devices (default: False)
  -c CLASS_NUM, --class_num CLASS_NUM
                        number of categories for classification task.
</code></pre>
</div>

<h2 id="参考文献">参考文献</h2>

<ol>
  <li>Huang P S, He X, Gao J, et al. Learning deep structured semantic models for web search using clickthrough data[C]//Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management. ACM, 2013: 2333-2338.</li>
  <li><a href="https://www.microsoft.com/en-us/research/project/mslr/">Microsoft Learning to Rank Datasets</a></li>
  <li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/wsdm2015.v3.pdf">Gao J, He X, Deng L. Deep Learning for Web Search and Natural Language Processing[J]. Microsoft Research Technical Report, 2015.</a></li>
</ol>

  </div>

  
</article>

      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">PaddlePaddle Model Zoo</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>
            
              PaddlePaddle Model Zoo
            
            </li>
            
            <li><a href="mailto:idl-paddle@baidu.com">idl-paddle@baidu.com</a></li>
            
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/PaddlePaddle"><span class="icon icon--github"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">PaddlePaddle</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/BaiduResearch"><span class="icon icon--twitter"><svg viewBox="0 0 16 16" width="16px" height="16px"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">BaiduResearch</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>PaddlePaddle, PArallel Distributed Deep LEarning, n Easy-to-use, Efficient, Flexible and Scalable Deep Learning Platform.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

 <!-- Baidu Analystics -->
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?b9a314ab40d04d805655aab1deee08ba";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			extensions: ["tex2jax.js"],
			jax: ["input/TeX", "output/HTML-CSS"],
			tex2jax: {
				inlineMath: [ ['$','$'], ["\\(","\\)"] ],
				displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
				processEscapes: true
			},
			"HTML-CSS": { availableFonts: ["TeX"] }
		});
	</script>

</html>
